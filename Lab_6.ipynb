{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlZ7+ArKz5ssKR5O3fG9Z9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Draw a Finite State Automaton which accepts all strings over {a, b} that end with two ’a’s, e.g. ‘aa’, ‘baa’, ‘bbaa’, ‘abaa’, ‘abaaa’, aaaaaa’, baaa’, etc. (10 MARKS)"
      ],
      "metadata": {
        "id": "jiCE3KuaQIx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "nruQg2MQPYRF",
        "outputId": "421406f9-2a6c-428f-e61a-e646b5f169a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digraph FSA {\n",
            "\trankdir=LR\n",
            "\tA [label=q0 shape=circle]\n",
            "\tB [label=q1 shape=circle]\n",
            "\tL [label=q2 shape=doublecircle]\n",
            "\tA -> A [label=b]\n",
            "\tA -> B [label=a]\n",
            "\tB -> A [label=b]\n",
            "\tB -> L [label=a]\n",
            "\tL -> A [label=b]\n",
            "\tL -> L [label=a]\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FSA.gv.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "FSA = Digraph(name='FSA')\n",
        "FSA.attr(rankdir='LR')\n",
        "FSA.node('A', 'q0', shape='circle')\n",
        "FSA.node('B', 'q1', shape='circle')\n",
        "FSA.node('L', 'q2', shape='doublecircle')\n",
        "\n",
        "FSA.edge('A', 'A', label='b')\n",
        "FSA.edge('A', 'B', label='a')\n",
        "FSA.edge('B', 'A', label='b')\n",
        "FSA.edge('B', 'L', label='a')\n",
        "FSA.edge('L', 'A', label='b')\n",
        "FSA.edge('L', 'L', label='a')\n",
        "\n",
        "print(FSA.source)\n",
        "FSA.view() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.\n",
        "Use the following sentence to explain the bag of word representation for Naïve Bayes classification.\n",
        "“John likes to watch movies. Mary likes movies too”\n",
        "Include the correct python code implementation for this purpose with the output."
      ],
      "metadata": {
        "id": "96L_tiC7Qsu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, string\n",
        "nltk.download('punkt')\n",
        "text = \"John likes to watch movies. Mary likes movies too\"\n",
        "Tokens = nltk.tokenize.word_tokenize(text)\n",
        "stopTokens = list(string.punctuation)\n",
        "\n",
        "filteredTokens = []\n",
        "\n",
        "for w in Tokens:\n",
        "    if w not in stopTokens :\n",
        "        filteredTokens.append(w)\n",
        "\n",
        "fdist = nltk.FreqDist(filteredTokens)\n",
        "print(\"\\n\",fdist.most_common())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFci45y0QudG",
        "outputId": "2ffec4bc-bb63-4027-ac88-4f8565f1721e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " [('likes', 2), ('movies', 2), ('John', 1), ('to', 1), ('watch', 1), ('Mary', 1), ('too', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Use the Maximum Matching Algorithm (Greedy Algorithm) to tokenize the following string. Can you confidently say the generated tokens are correct? Discuss your answer.\n",
        "“thesistermisslow”"
      ],
      "metadata": {
        "id": "rd6osDlmR3pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words\n",
        "nltk.download('words')\n",
        "\n",
        "import itertools\n",
        "words = [word for word in words.words() if len(word) > 1]\n",
        "print(words)\n",
        "s = 'thesistermisslow'\n",
        "\n",
        "def f(s, c=[]):\n",
        "  if not s:\n",
        "    return [tuple(c)]\n",
        "  return list(itertools.chain.from_iterable(f(s[len(word):], [*c.copy(), word]) for word in words if s.startswith(word)))\n",
        "for tokens in set(f(s)):\n",
        "  print(' '.join(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfLQMULFR6Pr",
        "outputId": "00043761-a784-4129-d23b-89bb03eb8078"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th es is term is slow\n",
            "thesis term is slow\n",
            "the si st er miss low\n",
            "the sis term is slow\n",
            "the sist er miss low\n",
            "the sister miss low\n",
            "th es ist er miss low\n"
          ]
        }
      ]
    }
  ]
}