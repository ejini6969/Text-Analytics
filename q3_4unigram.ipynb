{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/q3_4unigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1: Form a unigram language model**"
      ],
      "metadata": {
        "id": "CHHZrCm7r5lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "import nltk.tokenize\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "WnNAXmRHvVo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(r'Text Corpus.txt')\n",
        "text_corpus = file.read()\n",
        "print(text_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4KrFgUCvgP0",
        "outputId": "8a29f0b0-aafa-4e58-ca6d-c63a76ae55e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> He read a book </s>\n",
            "<s> I read a different book </s>\n",
            "<s> He read a book my Danielle </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the sentences in the text corpus into sentence tokens\n",
        "SentTokens = text_corpus.split(\"\\n\")\n",
        "\n",
        "# print the total number of sentences that found in the text corpus\n",
        "print(\"There are \", len(SentTokens), \"sentences in this text\\n\")\n",
        "# loop and display each sentence tokens\n",
        "for sent in SentTokens:\n",
        "  print(sent, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1-M7JJWvgYD",
        "outputId": "8034f2bd-5fb0-4455-c134-8b80e0a03374"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are  3 sentences in this text\n",
            "\n",
            "<s> He read a book </s> \n",
            "\n",
            "<s> I read a different book </s> \n",
            "\n",
            "<s> He read a book my Danielle </s> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove paddings\n",
        "# normalize to all lowercase before tokenize\n",
        "text_corpus = text_corpus.replace(\"<s>\", \"\").replace(\"</s>\", \"\").lower() \n",
        "tokens = nltk.tokenize.word_tokenize(text_corpus) \n",
        "\n",
        "# Set n to 1 for unigram model\n",
        "n, total_words, sets = 1, len(tokens), set(tokens)\n",
        "V = len(sets)  # unique words in corpus \n",
        "denominator = total_words + V + 1\n",
        "unigram_smooth = {}\n",
        "\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, [tokens]) \n",
        "model = MLE(n) # unigrams maximum likelihood estimation model\n",
        "model.fit(train_data, padded_sents)\n",
        "\n",
        "# unsmoothed probability\n",
        "print(\"\\n------------ Unsmoothed- ----------- \\n\")\n",
        "for x in sets:\n",
        "  print(\"P({0}) = {1}\".format(x,model.score(x)))\n",
        "\n",
        "# smoothed probability\n",
        "## calculate\n",
        "for x in sets:\n",
        "  prob = (model.counts[x] + 1) / denominator\n",
        "  unigram_smooth[x] = prob\n",
        "\n",
        "## display\n",
        "print(\"\\n------------ Smoothed- ------------ \\n\")\n",
        "for x in sets:\n",
        "  print(\"P({0}) = {1}\".format(x,unigram_smooth[x]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaMQz6ZH5bWa",
        "outputId": "72c889dc-f2d2-496e-bbc7-3ac0acc9f69d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Unsmoothed- ----------- \n",
            "\n",
            "P(i) = 0.06666666666666667\n",
            "P(he) = 0.13333333333333333\n",
            "P(a) = 0.2\n",
            "P(book) = 0.2\n",
            "P(read) = 0.2\n",
            "P(my) = 0.06666666666666667\n",
            "P(different) = 0.06666666666666667\n",
            "P(danielle) = 0.06666666666666667\n",
            "\n",
            "------------ Smoothed- ------------ \n",
            "\n",
            "P(i) = 0.08333333333333333\n",
            "P(he) = 0.125\n",
            "P(a) = 0.16666666666666666\n",
            "P(book) = 0.16666666666666666\n",
            "P(read) = 0.16666666666666666\n",
            "P(my) = 0.08333333333333333\n",
            "P(different) = 0.08333333333333333\n",
            "P(danielle) = 0.08333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute sentence probability based on smoothed unigram model above\n",
        "sentence = text_corpus.split(\"\\n\")\n",
        "for sent in sentence:\n",
        "  sent = word_tokenize(sent)\n",
        "  probability = 1\n",
        "  for word in sent:\n",
        "    probability *= unigram_smooth[word]\n",
        "  print(f'P(\"{\" \".join(sent)}\") = {probability}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WVtYL9w8OdE",
        "outputId": "ff1451a2-3bf5-44fb-8361-e98bd547a718"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(\"he read a book\") = 0.0005787037037037037\n",
            "P(\"i read a different book\") = 3.215020576131687e-05\n",
            "P(\"he read a book my danielle\") = 4.0187757201646085e-06\n"
          ]
        }
      ]
    }
  ]
}