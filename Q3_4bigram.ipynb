{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl5kQhaOwvmM2Aj4TmDbwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Q3_4bigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QMWbFap3E2U",
        "outputId": "63c8ace5-0b26-42f3-e4b1-3b24f4d71c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s> He read a book </s>', '<s> I read a different book </s>', '<s> He read a book my Danielle </s>']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Read Text File\n",
        "textFile = open(\"/content/Text Corpus.txt\", \"r\")\n",
        "corpus = [line.strip() for line in textFile]\n",
        "# Perform Tokenization and Decapitalization\n",
        "tokenizedCorpus = [nltk.tokenize.word_tokenize(corpus[i].lower()) for i in range(len(corpus))]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paddings = ['>', '<', 's', '/s']\n",
        "\n",
        "# Filter Paddings\n",
        "filteredCorpus = [[j for j in tokenizedCorpus[i] if j not in paddings] for i in range(len(tokenizedCorpus))]\n",
        "\n",
        "print(filteredCorpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2aCCKnQ3hfR",
        "outputId": "a3bc3f58-8c4d-41a7-e1f3-d944d26ed2fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['he', 'read', 'a', 'book'], ['i', 'read', 'a', 'different', 'book'], ['he', 'read', 'a', 'book', 'my', 'danielle']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import bigrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "\n",
        "# Insert Paddings at Both Ends and Form Bigram\n",
        "print(list(pad_both_ends(filteredCorpus[0], n=2)))\n",
        "print(list(bigrams(pad_both_ends(filteredCorpus[0], n=2))), \"\\n\")\n",
        "\n",
        "print(list(pad_both_ends(filteredCorpus[1], n=2)))\n",
        "print(list(bigrams(pad_both_ends(filteredCorpus[0], n=2))), \"\\n\")\n",
        "\n",
        "print(list(pad_both_ends(filteredCorpus[2], n=2)))\n",
        "print(list(bigrams(pad_both_ends(filteredCorpus[0], n=2))), \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcSZCyul3khd",
        "outputId": "d0a27d73-6381-455d-8e93-d82fde7cc3a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'he', 'read', 'a', 'book', '</s>']\n",
            "[('<s>', 'he'), ('he', 'read'), ('read', 'a'), ('a', 'book'), ('book', '</s>')] \n",
            "\n",
            "['<s>', 'i', 'read', 'a', 'different', 'book', '</s>']\n",
            "[('<s>', 'he'), ('he', 'read'), ('read', 'a'), ('a', 'book'), ('book', '</s>')] \n",
            "\n",
            "['<s>', 'he', 'read', 'a', 'book', 'my', 'danielle', '</s>']\n",
            "[('<s>', 'he'), ('he', 'read'), ('read', 'a'), ('a', 'book'), ('book', '</s>')] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Flattening\n",
        "print(list(flatten(pad_both_ends(sent, n=2) for sent in filteredCorpus)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJEGqfry3qVb",
        "outputId": "b77ffee1-53a0-4e6d-90d3-6be83704628d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'he', 'read', 'a', 'book', '</s>', '<s>', 'i', 'read', 'a', 'different', 'book', '</s>', '<s>', 'he', 'read', 'a', 'book', 'my', 'danielle', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n--------------------------------------------------')\n",
        "print('SMOOTHED BIGRAM PROBABILITY')\n",
        "print('------------------# Preprocess the Tokenized Text for Bigram Language Modelling')\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import Laplace # Laplace Smoothed\n",
        "from nltk.lm import Vocabulary\n",
        "\n",
        "# Create Lookup Vocabulary\n",
        "vocab = Vocabulary([\"he\", \"read\", \"a\", \"book\", \"i\", \"different\", \"my\", \"danielle\", \"<s>\", \"</s\"])\n",
        "\n",
        "#Bigram\n",
        "trainData, paddedSents = padded_everygram_pipeline(2, filteredCorpus)\n",
        "\n",
        "smoothedModel = Laplace(vocabulary = vocab, order = 2) # Training Bigram Laplace Smoothed Model\n",
        "smoothedModel.fit(trainData, paddedSents) # Building Model--------------------------------')\n",
        "\n",
        "print('P(He|<s>): ', round(smoothedModel.score('he', '<s>'.split()),4)) # P(He|<s>)\n",
        "print('P(I|<s>): ', round(smoothedModel.score('i', '<s>'.split()),4)) # P(I|<s>)\n",
        "print('P(read|<He>): ', round(smoothedModel.score('read', 'he'.split()),4)) # P(read|He)\n",
        "print('P(a|read): ', round(smoothedModel.score('a', 'read'.split()),4)) # P(a|read)\n",
        "print('P(book|a): ', round(smoothedModel.score('book', 'a'.split()),4)) # P(book|a)\n",
        "print('P(different|a): ', round(smoothedModel.score('different', 'a'.split()),4)) # P(different|a)\n",
        "print('P(my|book): ', round(smoothedModel.score('my', 'book'.split()),4)) # P(my|book)\n",
        "print('P(</s>|book): ', round(smoothedModel.score('</s>', 'book'.split()),4)) # P(</s>|book)\n",
        "print('P(read|I): ', round(smoothedModel.score('read', 'i'.split()),4)) # P(read|I)\n",
        "print('P(book|different): ', round(smoothedModel.score('book', 'different'.split()),4)) # P(book|different)\n",
        "print('P(Danielle|my): ', round(smoothedModel.score('danielle', 'my'.split()),4)) # P(Danielle|my)\n",
        "print('P(</s>|Danielle): ', round(smoothedModel.score('</s>', 'danielle'.split()),4)) # P(</s>|Danielle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJUAztii33U9",
        "outputId": "642bc31f-51dc-4740-e53c-f14f7a85203c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "SMOOTHED BIGRAM PROBABILITY\n",
            "------------------# Preprocess the Tokenized Text for Bigram Language Modelling\n",
            "P(He|<s>):  0.2143\n",
            "P(I|<s>):  0.1429\n",
            "P(read|<He>):  0.2308\n",
            "P(a|read):  0.2857\n",
            "P(book|a):  0.2143\n",
            "P(different|a):  0.1429\n",
            "P(my|book):  0.1429\n",
            "P(</s>|book):  0.2143\n",
            "P(read|I):  0.1667\n",
            "P(book|different):  0.1667\n",
            "P(Danielle|my):  0.1667\n",
            "P(</s>|Danielle):  0.1667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute sentence probability based on smoothed bigram model above\n",
        "for sent in corpus:\n",
        "  tk = sent.lower().split()\n",
        "  padded_bigram = list(bigrams(tk)) # generate bigrams for each sentence\n",
        "  probability = 1\n",
        "  for x1, x2 in padded_bigram:\n",
        "    val = smoothedModel.score(x2, x1.split())\n",
        "    probability *= val\n",
        "  print(f'P(\"{sent}\") = {probability}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax9Sq2Dm4-GL",
        "outputId": "d383bf76-8685-4564-fd81-43276d267861"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(\"<s> He read a book </s>\") = 0.0006487681414795117\n",
            "P(\"<s> I read a different book </s>\") = 3.4707760655282514e-05\n",
            "P(\"<s> He read a book my Danielle </s>\") = 1.2014224842213177e-05\n"
          ]
        }
      ]
    }
  ]
}