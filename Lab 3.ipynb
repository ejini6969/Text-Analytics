{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeO1BmmU8wMjtCk1Yf8ezn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Lab%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split() from python"
      ],
      "metadata": {
        "id": "4sau21VAc6WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am John and I am learning TXSA\"\n",
        "tokens = text.split()\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-oyQAnFdBXK",
        "outputId": "d9a2ff5f-ff57-4285-e44f-d087cb8c23df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'John', 'and', 'I', 'am', 'learning', 'TXSA']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I#am#John#and I am learning TXSA\"\n",
        "tokens = text.split(' ')\n",
        "print(tokens)\n",
        "tokens = text.split('#') # Only applicable if entire text contains special characters\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkplfIrUdSI8",
        "outputId": "73513ea4-c7cc-4c70-bada-3d23016d552b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I#am#John#and', 'I', 'am', 'learning', 'TXSA']\n",
            "['I', 'am', 'John', 'and I am learning TXSA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization using NLTK\n",
        "\n",
        "sentence segmentation = sentence tokenization\n",
        "\n",
        "word segmentation = word tokenization = tokenization"
      ],
      "metadata": {
        "id": "t1LFF89KyQRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\") # only for collab\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "text = \"This programme is designed to provide students with knowledge and applied skills in data science, big data analytics and business intelligence. It aims to develop analytical and investigative knowledge and skills using data science tools and techniques, and to enhance data science knowledge and critical interpretation skills. Students will understand the impact of data science upon modern processes and businesses, be able to identify, and implement specific tools, practices, features and techniques to enhance the analysis of data.\"\n",
        "\n",
        "# you can perform sentence tokenization and word tokenization\n",
        "sent = sent_tokenize(text)\n",
        "sent"
      ],
      "metadata": {
        "id": "mPM3PGpYyed_",
        "outputId": "2921f4cf-6fad-4a1e-ce38-ca66ccf028c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This programme is designed to provide students with knowledge and applied skills in data science, big data analytics and business intelligence.',\n",
              " 'It aims to develop analytical and investigative knowledge and skills using data science tools and techniques, and to enhance data science knowledge and critical interpretation skills.',\n",
              " 'Students will understand the impact of data science upon modern processes and businesses, be able to identify, and implement specific tools, practices, features and techniques to enhance the analysis of data.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent)"
      ],
      "metadata": {
        "id": "zM-2OOBZy3Sf",
        "outputId": "fd5344c4-930c-418f-d242-90c99e3b681e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens =  word_tokenize(text)\n",
        "tokens # punctuations / special characters are also separated as tokens"
      ],
      "metadata": {
        "id": "hTPL20TMy6KS",
        "outputId": "08aa4907-6b0f-4aea-fc50-387b84497ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'programme',\n",
              " 'is',\n",
              " 'designed',\n",
              " 'to',\n",
              " 'provide',\n",
              " 'students',\n",
              " 'with',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'applied',\n",
              " 'skills',\n",
              " 'in',\n",
              " 'data',\n",
              " 'science',\n",
              " ',',\n",
              " 'big',\n",
              " 'data',\n",
              " 'analytics',\n",
              " 'and',\n",
              " 'business',\n",
              " 'intelligence',\n",
              " '.',\n",
              " 'It',\n",
              " 'aims',\n",
              " 'to',\n",
              " 'develop',\n",
              " 'analytical',\n",
              " 'and',\n",
              " 'investigative',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'skills',\n",
              " 'using',\n",
              " 'data',\n",
              " 'science',\n",
              " 'tools',\n",
              " 'and',\n",
              " 'techniques',\n",
              " ',',\n",
              " 'and',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'data',\n",
              " 'science',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'critical',\n",
              " 'interpretation',\n",
              " 'skills',\n",
              " '.',\n",
              " 'Students',\n",
              " 'will',\n",
              " 'understand',\n",
              " 'the',\n",
              " 'impact',\n",
              " 'of',\n",
              " 'data',\n",
              " 'science',\n",
              " 'upon',\n",
              " 'modern',\n",
              " 'processes',\n",
              " 'and',\n",
              " 'businesses',\n",
              " ',',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'identify',\n",
              " ',',\n",
              " 'and',\n",
              " 'implement',\n",
              " 'specific',\n",
              " 'tools',\n",
              " ',',\n",
              " 'practices',\n",
              " ',',\n",
              " 'features',\n",
              " 'and',\n",
              " 'techniques',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'the',\n",
              " 'analysis',\n",
              " 'of',\n",
              " 'data',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "id": "Psa3PtK9zBWz",
        "outputId": "9d746750-d3c8-476d-91fb-9085bbdd47f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split() for python\n",
        "tokens_1 = text.split()\n",
        "tokens_1"
      ],
      "metadata": {
        "id": "R1k2vQ_yzJHt",
        "outputId": "f13a866b-9f84-4f6e-8538-6b250f7a1c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'programme',\n",
              " 'is',\n",
              " 'designed',\n",
              " 'to',\n",
              " 'provide',\n",
              " 'students',\n",
              " 'with',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'applied',\n",
              " 'skills',\n",
              " 'in',\n",
              " 'data',\n",
              " 'science,',\n",
              " 'big',\n",
              " 'data',\n",
              " 'analytics',\n",
              " 'and',\n",
              " 'business',\n",
              " 'intelligence.',\n",
              " 'It',\n",
              " 'aims',\n",
              " 'to',\n",
              " 'develop',\n",
              " 'analytical',\n",
              " 'and',\n",
              " 'investigative',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'skills',\n",
              " 'using',\n",
              " 'data',\n",
              " 'science',\n",
              " 'tools',\n",
              " 'and',\n",
              " 'techniques,',\n",
              " 'and',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'data',\n",
              " 'science',\n",
              " 'knowledge',\n",
              " 'and',\n",
              " 'critical',\n",
              " 'interpretation',\n",
              " 'skills.',\n",
              " 'Students',\n",
              " 'will',\n",
              " 'understand',\n",
              " 'the',\n",
              " 'impact',\n",
              " 'of',\n",
              " 'data',\n",
              " 'science',\n",
              " 'upon',\n",
              " 'modern',\n",
              " 'processes',\n",
              " 'and',\n",
              " 'businesses,',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'identify,',\n",
              " 'and',\n",
              " 'implement',\n",
              " 'specific',\n",
              " 'tools,',\n",
              " 'practices,',\n",
              " 'features',\n",
              " 'and',\n",
              " 'techniques',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'the',\n",
              " 'analysis',\n",
              " 'of',\n",
              " 'data.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split using textblob performing tokenization\n",
        "from textblob import TextBlob # directly available in colab\n",
        "print(TextBlob(text).sentences) # sentence tokenization\n",
        "print()\n",
        "print(TextBlob(text).words) # word tokenization, special characters are ommited"
      ],
      "metadata": {
        "id": "dLKlTTEQzQw2",
        "outputId": "256ef7c4-1dfb-4d27-eb85-8c135c6f09bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence(\"This programme is designed to provide students with knowledge and applied skills in data science, big data analytics and business intelligence.\"), Sentence(\"It aims to develop analytical and investigative knowledge and skills using data science tools and techniques, and to enhance data science knowledge and critical interpretation skills.\"), Sentence(\"Students will understand the impact of data science upon modern processes and businesses, be able to identify, and implement specific tools, practices, features and techniques to enhance the analysis of data.\")]\n",
            "\n",
            "['This', 'programme', 'is', 'designed', 'to', 'provide', 'students', 'with', 'knowledge', 'and', 'applied', 'skills', 'in', 'data', 'science', 'big', 'data', 'analytics', 'and', 'business', 'intelligence', 'It', 'aims', 'to', 'develop', 'analytical', 'and', 'investigative', 'knowledge', 'and', 'skills', 'using', 'data', 'science', 'tools', 'and', 'techniques', 'and', 'to', 'enhance', 'data', 'science', 'knowledge', 'and', 'critical', 'interpretation', 'skills', 'Students', 'will', 'understand', 'the', 'impact', 'of', 'data', 'science', 'upon', 'modern', 'processes', 'and', 'businesses', 'be', 'able', 'to', 'identify', 'and', 'implement', 'specific', 'tools', 'practices', 'features', 'and', 'techniques', 'to', 'enhance', 'the', 'analysis', 'of', 'data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removal of stop words and special characters\n"
      ],
      "metadata": {
        "id": "cZ-ggWL10PVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stoptokens = nltk.corpus.stopwords.words('english')\n",
        "print(stoptokens) # involve negative words such as wouldn't...\n",
        "# cannot remove such words in document analysis due to affecting overall satisfaction review rate from customers"
      ],
      "metadata": {
        "id": "eg62dFvG0Ul0",
        "outputId": "4624d9ec-9a6b-489b-d765-ff3a2593ea37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "print(list(string.punctuation))"
      ],
      "metadata": {
        "id": "PQAiinQr0wc5",
        "outputId": "8dce0ac8-4f28-4172-da41-8fcd05289aa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "how to remove stopwords and puctuations..."
      ],
      "metadata": {
        "id": "sg96Ue5m1rYc"
      }
    }
  ]
}