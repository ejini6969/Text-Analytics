{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnwlU1qvAwvFXGJg3QK5vN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Lecture_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language Models"
      ],
      "metadata": {
        "id": "45Plxzhnlbp_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvnqPzeqUJun",
        "outputId": "82a94b27-c5a2-4182-ed19-f1d7372c3100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "print(nltk.__version__) # must be 3.7 or above"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams, bigrams, everygrams, pad_sequence\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "text = \" I am learning text analytics\"\n",
        "tokens = nltk.tokenize.word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOBMQ6bul4T_",
        "outputId": "263f129d-57c6-4331-c793-ba54b740353b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(bigrams(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NbBSeFpmBzf",
        "outputId": "11d7bac2-4b60-40d3-a166-2781d7250f5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'am'), ('am', 'learning'), ('learning', 'text'), ('text', 'analytics')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(ngrams(tokens, n = 3)) # specify number of grams (trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIPTUjinmI4N",
        "outputId": "f12fbb5b-e316-4c60-a807-fee1bd496928"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'am', 'learning'),\n",
              " ('am', 'learning', 'text'),\n",
              " ('learning', 'text', 'analytics')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(everygrams(tokens, max_len = 3)) # start with unigram and ends with ngram for each sequence iteration (trigram for this case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mryRoL__maGF",
        "outputId": "24ab0091-84ea-425a-a201-1a74f78aa477"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I',),\n",
              " ('I', 'am'),\n",
              " ('I', 'am', 'learning'),\n",
              " ('am',),\n",
              " ('am', 'learning'),\n",
              " ('am', 'learning', 'text'),\n",
              " ('learning',),\n",
              " ('learning', 'text'),\n",
              " ('learning', 'text', 'analytics'),\n",
              " ('text',),\n",
              " ('text', 'analytics'),\n",
              " ('analytics',)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(pad_sequence(tokens, pad_left = True, left_pad_symbol = \"<s>\", pad_right = True, right_pad_symbol = \"</s>\", n = 3)) # unigram no need to consider left and right pad sequences\n",
        "# there will be (n - 1) left and end pad sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmW5E0Ttm2vH",
        "outputId": "260b8809-0eb1-43b7-bf7e-b26a5e7b577f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', '<s>', 'I', 'am', 'learning', 'text', 'analytics', '</s>', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sent = list(pad_sequence(tokens, pad_left = True, left_pad_symbol = \"<s>\", pad_right = True, right_pad_symbol = \"</s>\", n = 2))\n",
        "list(bigrams(padded_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wrSlt0pnn21",
        "outputId": "e0a8d6f9-8b47-406d-b940-4209b53a28f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', 'I'),\n",
              " ('I', 'am'),\n",
              " ('am', 'learning'),\n",
              " ('learning', 'text'),\n",
              " ('text', 'analytics'),\n",
              " ('analytics', '</s>')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# more simplified without providing much parameters\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "list(pad_both_ends(tokens, n = 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DczIJEgrn0JM",
        "outputId": "83a7973e-eb3e-4a8d-9490-1a54375695d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'I', 'am', 'learning', 'text', 'analytics', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate probabilities"
      ],
      "metadata": {
        "id": "__RvUsMtoLV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build maximum likelihood estimation model as a language model\n",
        "nltk.download(\"punkt\")\n",
        "text = \" I am learning text analytics\" \n",
        "tokenized_data = [list(map(str.lower, nltk.tokenize.word_tokenize(text)))] # apply normalization by lowering string's casing\n",
        "tokenized_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUnQayS5oMkd",
        "outputId": "406a772a-d920-45f0-8b72-85d4c0de2882"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'am', 'learning', 'text', 'analytics']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE # maximum likelihood estimation to build model\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline # preprocessing library imported to set data\n",
        "\n",
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_data) # trigram data\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_sents)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfDWB5lmoogE",
        "outputId": "05968770-7e91-4942-e4f8-dd5e3d4346f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.lm.models.MLE at 0x7fbc703a61c0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.counts['i'] # unigram count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGBZEe6dqWHW",
        "outputId": "16b28496-89f5-47fa-ef37-179838db2e4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.counts[['i']]['am'] # bigram count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLohBmRqekG",
        "outputId": "16d99a48-a76d-49be-a39d-aa8aa93249c2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score('am', 'i'.split()) # \"am\" after \"i\" -> P(am | i) = c(i am) / c(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Xc5GpGqEg-",
        "outputId": "98179989-d6af-48de-9108-f49f5abd8a3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}