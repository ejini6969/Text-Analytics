{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4tYvDe4apCLq3braMyLlj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before doing text sentiment and analysis, open the file and output its content \n",
        "file = open(\"/content/Data_1.txt\")\n",
        "text = file.read()\n",
        "print(text)\n",
        "file.close()  # Close the file to prevent data loss and corruption"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wchk8DBuxX7p",
        "outputId": "f4afe1e6-6b42-4e43-d3fd-8f13fc2da4b4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is one thing to automatically detect that a particular word occurs in a text, and to\n",
            "display some words that appear in the same context. However, we can also determine\n",
            "the location of a word in the text: how many words from the beginning it appears. This\n",
            "positional information can be displayed using a dispersion plot. Each stripe represents\n",
            "an instance of a word, and each row represents the entire text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"\\n\", \" \") # replace line separators with spaces\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B24vBCbL9kpV",
        "outputId": "2a1f3a80-ce4d-4763-b33c-64fe247ab141"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Form tokenization"
      ],
      "metadata": {
        "id": "QfjoAXGzxR_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Demonstrate sentence segmentation and report the output. "
      ],
      "metadata": {
        "id": "2BV5O-qWw-OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk import sent_tokenize \n",
        "\n",
        "tokens = sent_tokenize(text)\n",
        "print(\"\\nThere are a total of\", len(tokens), \"sentences in the text file.\\n\")\n",
        "\n",
        "num = 1\n",
        "for sentence in tokens:\n",
        "  print(f'{num}. {sentence}\\n')\n",
        "  num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sQd2MtcxDBo",
        "outputId": "187b2a81-4055-4385-fa51-5b343e6f88a6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are a total of 4 sentences in the text file.\n",
            "\n",
            "1. It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.\n",
            "\n",
            "2. However, we can also determine the location of a word in the text: how many words from the beginning it appears.\n",
            "\n",
            "3. This positional information can be displayed using a dispersion plot.\n",
            "\n",
            "4. Each stripe represents an instance of a word, and each row represents the entire text.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tDemonstrate word tokenisation using the split function, Regular Expression and NLTK packages separately and report the output."
      ],
      "metadata": {
        "id": "5HQO-Hmk9ff6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Python split() function\n",
        "word = text.split()\n",
        "print(word)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(word), \"words in the text file.\\n\")\n",
        "\n",
        "print(\"List of words that have leading or trailing punctuations: \\n\")\n",
        "num = 1\n",
        "for w in word:\n",
        "    for c in punctuation:\n",
        "      if w.startswith(c) or w.endswith(c):\n",
        "        print(f'{num}. {w}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "id": "N4AbMMLz9hmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e15dfa7-503a-47ff-b0f2-a5a4aa7dd262"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text,', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context.', 'However,', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text:', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word,', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text.']\n",
            "\n",
            "There are a total of 72 words in the text file.\n",
            "\n",
            "List of words that have leading or trailing punctuations: \n",
            "\n",
            "1. text,\n",
            "\n",
            "2. context.\n",
            "\n",
            "3. However,\n",
            "\n",
            "4. text:\n",
            "\n",
            "5. appears.\n",
            "\n",
            "6. plot.\n",
            "\n",
            "7. word,\n",
            "\n",
            "8. text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Regular Expression\n",
        "import re\n",
        "tokens_2 = re.findall(\"\\w+\", text)\n",
        "print(tokens_2)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(tokens_2), \"words in the text file.\\n\")\n",
        "\n",
        "print(\"List of words that have leading or trailing punctuations: \\n\")\n",
        "num = 1\n",
        "for t in tokens_2:\n",
        "    for c in punctuation:\n",
        "      if t.startswith(c) or t.endswith(c):\n",
        "        print(f'{num}. {t}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PG6rZWEjPS0",
        "outputId": "9e4f2b14-8c9b-44c1-aa93-c6da6928b8bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', 'However', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text']\n",
            "\n",
            "There are a total of 72 words in the text file.\n",
            "\n",
            "List of words that have leading or trailing punctuations: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens_3 = word_tokenize(text)\n",
        "print(tokens_3)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(tokens_3), \"tokens in the text file.\\n\")\n",
        "\n",
        "num = 1\n",
        "for t in tokens_3:\n",
        "    if t in punctuation:\n",
        "        print(f'{num}. {t}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JfbM-yVtr1d",
        "outputId": "c5a996d0-05b1-4f3b-bf86-4e129d0559e1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "\n",
            "There are a total of 80 tokens in the text file.\n",
            "\n",
            "1. ,\n",
            "\n",
            "2. .\n",
            "\n",
            "3. ,\n",
            "\n",
            "4. :\n",
            "\n",
            "5. .\n",
            "\n",
            "6. .\n",
            "\n",
            "7. ,\n",
            "\n",
            "8. .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Form word stemming "
      ],
      "metadata": {
        "id": "Rr3V2N4vw6pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tDemonstrate word stemming using Regular Expression, Porter Stemmer and Lancaster Stemmer and report the output. "
      ],
      "metadata": {
        "id": "h6wVWesN3Wpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "re_lst = []\n",
        "for x in tokens:\n",
        "  re_lst.append(re.sub(\"(ly|ed|ing|ies|es|s|ment)$\", \"\", x))\n",
        "print(re_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mSDdhet3av0",
        "outputId": "91592c58-a43c-499d-eaae-eae76db6bf78"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'i', 'one', 'th', 'to', 'automatical', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'beginn', 'it', 'appear', '.', 'Thi', 'positional', 'information', 'can', 'be', 'display', 'us', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represent', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represent', 'the', 'entire', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ps_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "for x in tokens:\n",
        "  ps_lst.append(ps.stem(x))\n",
        "print(ps_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d09_f2Rx4Y7p",
        "outputId": "f1201b29-2eb4-4ca1-f66e-87e9bb71458b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it', 'is', 'one', 'thing', 'to', 'automat', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'locat', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'mani', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'use', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'instanc', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lancaster Stemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "ls = LancasterStemmer()\n",
        "ls_lst = []\n",
        "for x in tokens:\n",
        "  ls_lst.append(ls.stem(x))\n",
        "print(ls_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alQE59vt5HUe",
        "outputId": "3f87edd9-5cf0-4ce1-9807-5809b4856a08"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it', 'is', 'on', 'thing', 'to', 'autom', 'detect', 'that', 'a', 'particul', 'word', 'occ', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'som', 'word', 'that', 'appear', 'in', 'the', 'sam', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'loc', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'us', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'inst', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tExplain the differences among Regular Expression stemmer, Porter Stemmer and Lancaster Stemmer using the obtained output"
      ],
      "metadata": {
        "id": "Gily_ER6BBUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Regular Expression       vs       Porter Stemmer       vs       Lancaster Stemmer\")\n",
        "for r, p, l in zip(re_lst, ps_lst, ls_lst):\n",
        "  if r != p or p != l or r != l:\n",
        "    print(r.ljust(35, ' '), p.ljust(35, ' '), l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umpiHpbN7yCm",
        "outputId": "f753277d-9baf-4a2f-c2b9-e3923ce58896"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular Expression       vs       Porter Stemmer       vs       Lancaster Stemmer\n",
            "It                                  it                                  it\n",
            "i                                   is                                  is\n",
            "one                                 one                                 on\n",
            "th                                  thing                               thing\n",
            "automatical                         automat                             autom\n",
            "particular                          particular                          particul\n",
            "occur                               occur                               occ\n",
            "some                                some                                som\n",
            "same                                same                                sam\n",
            "However                             howev                               howev\n",
            "determine                           determin                            determin\n",
            "location                            locat                               loc\n",
            "many                                mani                                many\n",
            "beginn                              begin                               begin\n",
            "Thi                                 thi                                 thi\n",
            "positional                          posit                               posit\n",
            "information                         inform                              inform\n",
            "us                                  use                                 us\n",
            "dispersion                          dispers                             dispers\n",
            "Each                                each                                each\n",
            "represent                           repres                              repres\n",
            "instance                            instanc                             inst\n",
            "represent                           repres                              repres\n",
            "entire                              entir                               entir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Filter stop words and punctuation "
      ],
      "metadata": {
        "id": "ipmAWFhbDe11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tDemonstrate stop words and punctuations removal from the given text corpus and report the output suitably. "
      ],
      "metadata": {
        "id": "t8xG5wgQDffQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words removal\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "stoptokens = nltk.corpus.stopwords.words(\"english\") # list of stopwords\n",
        "tokens = text.split()\n",
        "\n",
        "print(\"Text before stop words removal:\\n\\n\", text, \"\\n\")\n",
        "sw_removal = \"\"\n",
        "for w in tokens:\n",
        "  if w not in stoptokens:\n",
        "    sw_removal += w + \" \"\n",
        "print(\"Text after stop words removal:\\n\\n\", sw_removal, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB1jMqxvDiG3",
        "outputId": "4ab4a8a6-675c-4cc5-a18b-5e448886f3b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before stop words removal:\n",
            "\n",
            " It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. \n",
            "\n",
            "Text after stop words removal:\n",
            "\n",
            " It one thing automatically detect particular word occurs text, display words appear context. However, also determine location word text: many words beginning appears. This positional information displayed using dispersion plot. Each stripe represents instance word, row represents entire text.  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuation removal\n",
        "from string import punctuation\n",
        "\n",
        "print(\"Text before punctuation removal:\\n\\n\", sw_removal)\n",
        "pct_removal = \"\"\n",
        "for c in sw_removal:\n",
        "  if c not in punctuation:\n",
        "    pct_removal += c\n",
        "print(\"\\nText after punctuation removal:\\n\\n\", pct_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Q9PjO3Lpdr",
        "outputId": "c579e16f-1f7f-4e84-9882-20cba6ef5dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before punctuation removal:\n",
            "\n",
            " It one thing automatically detect particular word occurs text, display words appear context. However, also determine location word text: many words beginning appears. This positional information displayed using dispersion plot. Each stripe represents instance word, row represents entire text. \n",
            "\n",
            "Text after punctuation removal:\n",
            "\n",
            " It one thing automatically detect particular word occurs text display words appear context However also determine location word text many words beginning appears This positional information displayed using dispersion plot Each stripe represents instance word row represents entire text \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tReport the stop words found in the given text corpus. "
      ],
      "metadata": {
        "id": "f9dRJiPnutEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "stoptokens = nltk.corpus.stopwords.words(\"english\") # list of stopwords\n",
        "print(\"All stop words found in NLTK corpus:\\n\", stoptokens, \"\\n\")\n",
        "\n",
        "print(\"List of stop words found in the text corpus: \\n\")\n",
        "num = 1\n",
        "tokens = text.lower().split() # must convert to lowercase first since all stop words in nltk corpus are lowercase\n",
        "for x in tokens:\n",
        "  if x in stoptokens:\n",
        "    print(f'{num}. {x}')\n",
        "    num += 1\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "suoB154jurye",
        "outputId": "8686f4c8-8687-401c-8cd6-8355d5c55484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All stop words found in NLTK corpus:\n",
            " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"] \n",
            "\n",
            "List of stop words found in the text corpus: \n",
            "\n",
            "1. it\n",
            "2. is\n",
            "3. to\n",
            "4. that\n",
            "5. a\n",
            "6. in\n",
            "7. a\n",
            "8. and\n",
            "9. to\n",
            "10. some\n",
            "11. that\n",
            "12. in\n",
            "13. the\n",
            "14. same\n",
            "15. we\n",
            "16. can\n",
            "17. the\n",
            "18. of\n",
            "19. a\n",
            "20. in\n",
            "21. the\n",
            "22. how\n",
            "23. from\n",
            "24. the\n",
            "25. it\n",
            "26. this\n",
            "27. can\n",
            "28. be\n",
            "29. a\n",
            "30. each\n",
            "31. an\n",
            "32. of\n",
            "33. a\n",
            "34. and\n",
            "35. each\n",
            "36. the\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Form Parts of Speech (POS) taggers & Syntactic Analysers "
      ],
      "metadata": {
        "id": "ETA4B5ndzD8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before doing text sentiment and analysis, open the file and output its content \n",
        "file = open(\"/content/Data_2.txt\")\n",
        "text2 = file.read()\n",
        "print(text2)\n",
        "file.close()  # Close the file to prevent data loss and corruption"
      ],
      "metadata": {
        "id": "OonIQlDIzZrz",
        "outputId": "31ad3f8b-9220-4dd0-a88d-ac794f78f427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The big black dog barked at the white cat and chased away.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tDemonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output"
      ],
      "metadata": {
        "id": "VxIYaRJnzPaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK POS tagger\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"tagsets\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text2)\n",
        "nltk_pos = nltk.pos_tag(tokens)\n",
        "print(nltk_pos, \"\\n\")"
      ],
      "metadata": {
        "id": "JYL4epA3zDSY",
        "outputId": "f4d56ec5-9f3a-4ad7-b1d8-0f43690530ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB'), ('.', '.')] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# textblob POS tagger\n",
        "from textblob import TextBlob\n",
        "tokens = TextBlob(text2)\n",
        "textblob_pos = tokens.tags\n",
        "print(textblob_pos)"
      ],
      "metadata": {
        "id": "tL34HeiO5bbx",
        "outputId": "4d172d47-ace8-45e7-84f9-5ad1f0602ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression tagger\n",
        "from nltk.tag.sequential import RegexpTagger as RegT\n",
        "\n",
        "patterns = [\n",
        "     (r'.*ing$', 'VBG'),               # gerunds\n",
        "     (r'.*ed$', 'VBD'),                # simple past\n",
        "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
        "     (r'.*ould(n\\'t)?$', 'MD'),        # modals\n",
        "     (r'.*(\\'s|s\\')$', 'NN$'),         # possessive nouns\n",
        "     (r'.*s$', 'NNS'),                 # plural nouns\n",
        "     (r'^-?\\d+(.\\d+)?$', 'CD'),        # cardinal numbers\n",
        "     (r'.*ment$', 'NN'),               # i.e. wonderment\n",
        "     (r'.*ful$', 'JJ'),                # i.e. wonderful\n",
        "     (r'.*', 'NN')                     # nouns (default)\n",
        " ]\n",
        "\n",
        "tagger = RegT(patterns)\n",
        "tokens = word_tokenize(text2)\n",
        "regex_pos = tagger.tag(tokens)\n",
        "print(regex_pos)             "
      ],
      "metadata": {
        "id": "3wvW840y5w7j",
        "outputId": "bf98d3bf-2afc-4ecc-d59e-a54237bf9318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'NN'), ('big', 'NN'), ('black', 'NN'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'NN'), ('the', 'NN'), ('white', 'NN'), ('cat', 'NN'), ('and', 'NN'), ('chased', 'VBD'), ('away', 'NN'), ('.', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tExplain the differences of the POS taggers using the output obtained in the above question"
      ],
      "metadata": {
        "id": "JSu_kmFpArFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"          \".join(x for x in [\"tokens\", \"NLTK POS tagger\", \"Textblob POS tagger\", \"Regular Expression POS tagger\"]))\n",
        "\n",
        "for x, y, z in zip(nltk_pos, textblob_pos, regex_pos):\n",
        "  print(x[0].ljust(20, ' '), x[1].ljust(25, ' '), y[1].ljust(30, ' '), z[1])"
      ],
      "metadata": {
        "id": "ZbMlvmz__KQe",
        "outputId": "39e4c8ca-50a5-42f8-d7a0-292cdafb04b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens          NLTK POS tagger          Textblob POS tagger          Regular Expression POS tagger\n",
            "The                  DT                        DT                             NN\n",
            "big                  JJ                        JJ                             NN\n",
            "black                JJ                        JJ                             NN\n",
            "dog                  NN                        NN                             NN\n",
            "barked               VBD                       VBD                            VBD\n",
            "at                   IN                        IN                             NN\n",
            "the                  DT                        DT                             NN\n",
            "white                JJ                        JJ                             NN\n",
            "cat                  NN                        NN                             NN\n",
            "and                  CC                        CC                             NN\n",
            "chased               VBD                       VBD                            VBD\n",
            "away                 RB                        RB                             NN\n"
          ]
        }
      ]
    }
  ]
}