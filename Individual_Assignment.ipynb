{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlMHdOIyNo8mzcWyPlS8RB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before doing text sentiment and analysis, open the file and output its content \n",
        "file = open(\"/content/Data_1.txt\")\n",
        "text = file.read()\n",
        "print(text)\n",
        "file.close()  # Close the file to prevent data loss and corruption"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wchk8DBuxX7p",
        "outputId": "4ab0f790-b08c-4764-9632-83d6f8ae8353"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is one thing to automatically detect that a particular word occurs in a text, and to\n",
            "display some words that appear in the same context. However, we can also determine\n",
            "the location of a word in the text: how many words from the beginning it appears. This\n",
            "positional information can be displayed using a dispersion plot. Each stripe represents\n",
            "an instance of a word, and each row represents the entire text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"\\n\", \" \") # replace line separators with spaces\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B24vBCbL9kpV",
        "outputId": "7b6639b8-e69c-40c2-eff0-29cef749279c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Form tokenization"
      ],
      "metadata": {
        "id": "QfjoAXGzxR_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Demonstrate sentence segmentation and report the output. "
      ],
      "metadata": {
        "id": "2BV5O-qWw-OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk import sent_tokenize \n",
        "\n",
        "tokens = sent_tokenize(text)\n",
        "print(\"\\nThere are a total of\", len(tokens), \"sentences in the text file.\\n\")\n",
        "\n",
        "num = 1\n",
        "for sentence in tokens:\n",
        "  print(f'{num}. {sentence}\\n') \n",
        "  print(str(num) + '. ' + sentence + '\\n')\n",
        "  num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sQd2MtcxDBo",
        "outputId": "287e2e40-a672-49bc-accb-441c5ad645ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are a total of 4 sentences in the text file.\n",
            "\n",
            "1. It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.\n",
            "\n",
            "1. It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.\n",
            "\n",
            "2. However, we can also determine the location of a word in the text: how many words from the beginning it appears.\n",
            "\n",
            "2. However, we can also determine the location of a word in the text: how many words from the beginning it appears.\n",
            "\n",
            "3. This positional information can be displayed using a dispersion plot.\n",
            "\n",
            "3. This positional information can be displayed using a dispersion plot.\n",
            "\n",
            "4. Each stripe represents an instance of a word, and each row represents the entire text.\n",
            "\n",
            "4. Each stripe represents an instance of a word, and each row represents the entire text.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tDemonstrate word tokenisation using the split function, Regular Expression and NLTK packages separately and report the output."
      ],
      "metadata": {
        "id": "5HQO-Hmk9ff6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Python split() function\n",
        "word = text.split()\n",
        "print(word)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(word), \"words in the text file.\\n\")\n",
        "\n",
        "print(\"List of words that have leading or trailing punctuations: \\n\")\n",
        "num = 1\n",
        "for w in word:\n",
        "    for c in punctuation:\n",
        "      if w.startswith(c) or w.endswith(c):\n",
        "        print(f'{num}. {w}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "id": "N4AbMMLz9hmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7373637b-8b2d-4faa-88d2-74e183b7690a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text,', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context.', 'However,', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text:', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word,', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text.']\n",
            "\n",
            "There are a total of 72 words in the text file.\n",
            "\n",
            "List of words that have leading or trailing punctuations: \n",
            "\n",
            "1. text,\n",
            "\n",
            "2. context.\n",
            "\n",
            "3. However,\n",
            "\n",
            "4. text:\n",
            "\n",
            "5. appears.\n",
            "\n",
            "6. plot.\n",
            "\n",
            "7. word,\n",
            "\n",
            "8. text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Regular Expression\n",
        "import re\n",
        "tokens_2 = re.findall(\"\\w+\", text)\n",
        "print(tokens_2)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(tokens_2), \"words in the text file.\\n\")\n",
        "\n",
        "print(\"List of words that have leading or trailing punctuations: \\n\")\n",
        "num = 1\n",
        "for t in tokens_2:\n",
        "    for c in punctuation:\n",
        "      if t.startswith(c) or t.endswith(c):\n",
        "        print(f'{num}. {t}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PG6rZWEjPS0",
        "outputId": "62ad8b98-5041-449c-d38a-248409d5cb44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', 'However', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text']\n",
            "\n",
            "There are a total of 72 words in the text file.\n",
            "\n",
            "List of words that have leading or trailing punctuations: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens_3 = word_tokenize(text)\n",
        "print(tokens_3)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(tokens_3), \"tokens in the text file.\\n\")\n",
        "\n",
        "num = 1\n",
        "for t in tokens_3:\n",
        "    if t in punctuation:\n",
        "        print(f'{num}. {t}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JfbM-yVtr1d",
        "outputId": "f4cdab88-e2c9-4e71-e57f-bb9a1a517d7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "\n",
            "There are a total of 80 tokens in the text file.\n",
            "\n",
            "1. ,\n",
            "\n",
            "2. .\n",
            "\n",
            "3. ,\n",
            "\n",
            "4. :\n",
            "\n",
            "5. .\n",
            "\n",
            "6. .\n",
            "\n",
            "7. ,\n",
            "\n",
            "8. .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Form word stemming "
      ],
      "metadata": {
        "id": "Rr3V2N4vw6pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tDemonstrate word stemming using Regular Expression, Porter Stemmer and Lancaster Stemmer and report the output. "
      ],
      "metadata": {
        "id": "h6wVWesN3Wpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "re_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "regexp = RegexpStemmer(\"(ly|ed|ing|ies|es|s|ment)$\")\n",
        "print(\"List of tokens before stemming:\\n\", tokens)\n",
        "for x in tokens:\n",
        "  r = regexp.stem(x)\n",
        "  re_lst.append(r)\n",
        "print(\"List of tokens after stemming:\\n\", re_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mSDdhet3av0",
        "outputId": "7b6a2d40-f532-4f1a-f10a-fba46bbd3f39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens before stemming:\n",
            " ['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "List of tokens after stemming:\n",
            " ['It', 'i', 'one', 'th', 'to', 'automatical', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'beginn', 'it', 'appear', '.', 'Thi', 'positional', 'information', 'can', 'be', 'display', 'us', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represent', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represent', 'the', 'entire', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ps_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "print(\"List of tokens before stemming:\\n\", tokens)\n",
        "for x in tokens:\n",
        "  ps_lst.append(ps.stem(x))\n",
        "print(\"List of tokens after stemming:\\n\", ps_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d09_f2Rx4Y7p",
        "outputId": "3b8f393b-5c96-4f22-a39a-6ab04a9eb03e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens before stemming:\n",
            " ['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "List of tokens after stemming:\n",
            " ['it', 'is', 'one', 'thing', 'to', 'automat', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'locat', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'mani', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'use', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'instanc', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lancaster Stemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "ls = LancasterStemmer()\n",
        "ls_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "print(\"List of tokens before stemming:\\n\", tokens)\n",
        "for x in tokens:\n",
        "  ls_lst.append(ls.stem(x))\n",
        "print(\"List of tokens after stemming:\\n\", ls_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alQE59vt5HUe",
        "outputId": "4e79965f-730a-49b4-b28e-31cf792beaf0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens before stemming:\n",
            " ['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "List of tokens after stemming:\n",
            " ['it', 'is', 'on', 'thing', 'to', 'autom', 'detect', 'that', 'a', 'particul', 'word', 'occ', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'som', 'word', 'that', 'appear', 'in', 'the', 'sam', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'loc', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'us', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'inst', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tExplain the differences among Regular Expression stemmer, Porter Stemmer and Lancaster Stemmer using the obtained output"
      ],
      "metadata": {
        "id": "Gily_ER6BBUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Row number       Original token          Regular Expression          Porter Stemmer          Lancaster Stemmer\")\n",
        "\n",
        "i = 1\n",
        "tokens = word_tokenize(text)\n",
        "for t, r, p, l in zip(tokens, re_lst, ps_lst, ls_lst):\n",
        "  if r != p or p != l or r != l:\n",
        "    print(str(i).ljust(20, ' '), t.ljust(25, ' '), r.ljust(25, ' '), p.ljust(25, ' '), l)\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umpiHpbN7yCm",
        "outputId": "31366db5-2c87-4634-d326-b9c53147821a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row number       Original token          Regular Expression          Porter Stemmer          Lancaster Stemmer\n",
            "1                    It                        It                        it                        it\n",
            "2                    is                        i                         is                        is\n",
            "3                    one                       one                       one                       on\n",
            "4                    thing                     th                        thing                     thing\n",
            "5                    automatically             automatical               automat                   autom\n",
            "6                    particular                particular                particular                particul\n",
            "7                    occurs                    occur                     occur                     occ\n",
            "8                    some                      some                      some                      som\n",
            "9                    same                      same                      same                      sam\n",
            "10                   However                   However                   howev                     howev\n",
            "11                   determine                 determine                 determin                  determin\n",
            "12                   location                  location                  locat                     loc\n",
            "13                   many                      many                      mani                      many\n",
            "14                   beginning                 beginn                    begin                     begin\n",
            "15                   This                      Thi                       thi                       thi\n",
            "16                   positional                positional                posit                     posit\n",
            "17                   information               information               inform                    inform\n",
            "18                   using                     us                        use                       us\n",
            "19                   dispersion                dispersion                dispers                   dispers\n",
            "20                   Each                      Each                      each                      each\n",
            "21                   represents                represent                 repres                    repres\n",
            "22                   instance                  instance                  instanc                   inst\n",
            "23                   represents                represent                 repres                    repres\n",
            "24                   entire                    entire                    entir                     entir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Filter stop words and punctuation "
      ],
      "metadata": {
        "id": "ipmAWFhbDe11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tDemonstrate stop words and punctuations removal from the given text corpus and report the output suitably. "
      ],
      "metadata": {
        "id": "t8xG5wgQDffQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words removal\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "stoptokens = nltk.corpus.stopwords.words(\"english\") # list of stopwords\n",
        "tokens = word_tokenize(text.lower()) # must convert to lowercase first since all stop words in nltk corpus are lowercase\n",
        "\n",
        "print(\"Text before stop words removal:\\n\\n\", text, \"\\n\")\n",
        "sw_removal = \"\"\n",
        "for w in tokens:\n",
        "  if w not in stoptokens:\n",
        "    sw_removal += w + \" \"\n",
        "print(\"Text after stop words removal:\\n\\n\", sw_removal, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB1jMqxvDiG3",
        "outputId": "87815853-b2f0-4e73-f48e-7924e1cd8213"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before stop words removal:\n",
            "\n",
            " It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. \n",
            "\n",
            "Text after stop words removal:\n",
            "\n",
            " one thing automatically detect particular word occurs text , display words appear context . however , also determine location word text : many words beginning appears . positional information displayed using dispersion plot . stripe represents instance word , row represents entire text .  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuation removal\n",
        "from string import punctuation\n",
        "\n",
        "print(\"Text before punctuation removal:\\n\\n\", sw_removal)\n",
        "pct_removal = \"\"\n",
        "for c in sw_removal:\n",
        "  if c not in punctuation:\n",
        "    pct_removal += c\n",
        "print(\"\\nText after punctuation removal:\\n\\n\", pct_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Q9PjO3Lpdr",
        "outputId": "91f1a0d9-1eaf-4360-86e1-75370fb110ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before punctuation removal:\n",
            "\n",
            " one thing automatically detect particular word occurs text , display words appear context . however , also determine location word text : many words beginning appears . positional information displayed using dispersion plot . stripe represents instance word , row represents entire text . \n",
            "\n",
            "Text after punctuation removal:\n",
            "\n",
            " one thing automatically detect particular word occurs text  display words appear context  however  also determine location word text  many words beginning appears  positional information displayed using dispersion plot  stripe represents instance word  row represents entire text  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tReport the stop words found in the given text corpus. "
      ],
      "metadata": {
        "id": "f9dRJiPnutEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "stoptokens = nltk.corpus.stopwords.words(\"english\") # list of stopwords\n",
        "print(\"All stop words found in NLTK corpus:\\n\", stoptokens, \"\\n\")\n",
        "\n",
        "print(\"List of stop words found in the text corpus: \\n\")\n",
        "num = 1\n",
        "tokens = word_tokenize(text.lower()) # must convert to lowercase first since all stop words in nltk corpus are lowercase\n",
        "for x in tokens:\n",
        "  if x in stoptokens:\n",
        "    print(f'{num}. {x}')\n",
        "    num += 1\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "suoB154jurye",
        "outputId": "7ed79b94-abd5-44e2-f836-05198d11c92e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All stop words found in NLTK corpus:\n",
            " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"] \n",
            "\n",
            "List of stop words found in the text corpus: \n",
            "\n",
            "1. it\n",
            "2. is\n",
            "3. to\n",
            "4. that\n",
            "5. a\n",
            "6. in\n",
            "7. a\n",
            "8. and\n",
            "9. to\n",
            "10. some\n",
            "11. that\n",
            "12. in\n",
            "13. the\n",
            "14. same\n",
            "15. we\n",
            "16. can\n",
            "17. the\n",
            "18. of\n",
            "19. a\n",
            "20. in\n",
            "21. the\n",
            "22. how\n",
            "23. from\n",
            "24. the\n",
            "25. it\n",
            "26. this\n",
            "27. can\n",
            "28. be\n",
            "29. a\n",
            "30. each\n",
            "31. an\n",
            "32. of\n",
            "33. a\n",
            "34. and\n",
            "35. each\n",
            "36. the\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Form Parts of Speech (POS) taggers & Syntactic Analysers "
      ],
      "metadata": {
        "id": "ETA4B5ndzD8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before doing text sentiment and analysis, open the file and output its content \n",
        "file = open(\"/content/Data_2.txt\")\n",
        "text2 = file.read()\n",
        "print(text2)\n",
        "file.close()  # Close the file to prevent data loss and corruption"
      ],
      "metadata": {
        "id": "OonIQlDIzZrz",
        "outputId": "ccf2e5a0-f279-46f7-afdc-c8a727bb921b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The big black dog barked at the white cat and chased away.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tDemonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output"
      ],
      "metadata": {
        "id": "VxIYaRJnzPaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK POS tagger\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text2)\n",
        "nltk_pos = nltk.pos_tag(tokens)\n",
        "\n",
        "print(\"Row number     Token        Tag\")\n",
        "num = 1\n",
        "for (token, pos) in nltk_pos:\n",
        "  print(f'{str(num).ljust(16, \" \")}{token.ljust(13, \" \")}{pos}')\n",
        "  num += 1"
      ],
      "metadata": {
        "id": "JYL4epA3zDSY",
        "outputId": "056a5bd3-5244-4857-8b0c-6fced36290d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row number     Token        Tag\n",
            "1               The          DT\n",
            "2               big          JJ\n",
            "3               black        JJ\n",
            "4               dog          NN\n",
            "5               barked       VBD\n",
            "6               at           IN\n",
            "7               the          DT\n",
            "8               white        JJ\n",
            "9               cat          NN\n",
            "10              and          CC\n",
            "11              chased       VBD\n",
            "12              away         RB\n",
            "13              .            .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# textblob POS tagger\n",
        "from textblob import TextBlob\n",
        "tokens = TextBlob(text2)\n",
        "textblob_pos = tokens.tags\n",
        "\n",
        "print(\"Row number     Token        Tag\")\n",
        "num = 1\n",
        "for (token, pos) in textblob_pos:\n",
        "  print(f'{str(num).ljust(16, \" \")}{token.ljust(13, \" \")}{pos}')\n",
        "  num += 1"
      ],
      "metadata": {
        "id": "tL34HeiO5bbx",
        "outputId": "afea00c8-d0ff-4bcf-f577-92930fb673fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row number     Token        Tag\n",
            "1               The          DT\n",
            "2               big          JJ\n",
            "3               black        JJ\n",
            "4               dog          NN\n",
            "5               barked       VBD\n",
            "6               at           IN\n",
            "7               the          DT\n",
            "8               white        JJ\n",
            "9               cat          NN\n",
            "10              and          CC\n",
            "11              chased       VBD\n",
            "12              away         RB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression tagger\n",
        "from nltk.tag.sequential import RegexpTagger as RegT\n",
        "\n",
        "patterns = [\n",
        "     (r'.*ing$', 'VBG'),               # gerunds\n",
        "     (r'.*ed$', 'VBD'),                # simple past\n",
        "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
        "     (r'.*ould(n\\'t)?$', 'MD'),        # modals\n",
        "     (r'.*(\\'s|s\\')$', 'NN$'),         # possessive nouns\n",
        "     (r'.*s$', 'NNS'),                 # plural nouns\n",
        "     (r'^-?\\d+(.\\d+)?$', 'CD'),        # cardinal numbers\n",
        "     (r'.*ment$', 'NN'),               # i.e. wonderment\n",
        "     (r'.*ful$', 'JJ'),                # i.e. wonderful\n",
        "     (r'.*', 'NN')                     # nouns (default)\n",
        " ]\n",
        "\n",
        "tagger = RegT(patterns)\n",
        "tokens = word_tokenize(text2)\n",
        "regex_pos = tagger.tag(tokens)\n",
        "\n",
        "print(\"Row number     Token        Tag\")\n",
        "num = 1\n",
        "for (token, pos) in regex_pos:\n",
        "  print(f'{str(num).ljust(16, \" \")}{token.ljust(13, \" \")}{pos}')\n",
        "  num += 1    "
      ],
      "metadata": {
        "id": "3wvW840y5w7j",
        "outputId": "7f1fa179-c79d-40fe-fead-3664ba90143f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row number     Token        Tag\n",
            "1               The          NN\n",
            "2               big          NN\n",
            "3               black        NN\n",
            "4               dog          NN\n",
            "5               barked       VBD\n",
            "6               at           NN\n",
            "7               the          NN\n",
            "8               white        NN\n",
            "9               cat          NN\n",
            "10              and          NN\n",
            "11              chased       VBD\n",
            "12              away         NN\n",
            "13              .            NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tExplain the differences of the POS taggers using the output obtained in the above question"
      ],
      "metadata": {
        "id": "JSu_kmFpArFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import zip_longest\n",
        "\n",
        "print(\"          \".join(x for x in [\"tokens\", \"NLTK POS tagger\", \"Textblob POS tagger\", \"Regular Expression POS tagger\"]))\n",
        "\n",
        "for x, y, z in zip_longest([nltk_pos, textblob_pos, regex_pos], \"\"):\n",
        "  print(x[0].ljust(20, ' '), x[1].ljust(25, ' '), y[1].ljust(30, ' '), z[1])"
      ],
      "metadata": {
        "id": "ZbMlvmz__KQe",
        "outputId": "74f9b359-c703-41cb-e203-8ec5a6f96726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens          NLTK POS tagger          Textblob POS tagger          Regular Expression POS tagger\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3210207f3cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"          \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NLTK POS tagger\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Textblob POS tagger\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Regular Expression POS tagger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_longest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnltk_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextblob_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Draw possible parse trees for the given sentence using suitable python codes and report the output along with the code"
      ],
      "metadata": {
        "id": "Gov3JQaWub0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "### CREATE VIRTUAL DISPLAY ###\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0.\n",
        "\n",
        "%matplotlib inline\n",
        "### INSTALL GHOSTSCRIPT (Required to display NLTK trees) ###\n",
        "!apt install ghostscript python3-tk\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "!pip install svgling"
      ],
      "metadata": {
        "id": "xZB_YejLulDD",
        "outputId": "83b7bfd6-428f-4af0-f4d5-ce9d7ee9f540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 785 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Ign:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.12\n",
            "Err:1 http://security.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.12\n",
            "  404  Not Found [IP: 91.189.91.39 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.12_amd64.deb  404  Not Found [IP: 91.189.91.39 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ghostscript is already the newest version (9.26~dfsg+0-0ubuntu0.18.04.17).\n",
            "python3-tk is already the newest version (3.6.9-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "\n",
        "\"\"\"\n",
        "tk = TextBlob(text2.lower()) # use .lower() to put in normalized form\n",
        "textblob_pos = tk.tags\n",
        "tokens = [x[0] for x in textblob_pos]\n",
        "print(tokens)\n",
        "\"\"\"\n",
        "\n",
        "text3 = nltk.CFG.fromstring(\"\"\"\n",
        "S -> NP VP \n",
        "NP -> DT NN | DT NOM \n",
        "NOM -> ADJ ADJ NN | ADJ NN | ADJ NOM\n",
        "VP -> V | VP PP | VP CC VP | V ADV \n",
        "PP -> P NP\n",
        "V -> 'barked' | 'chased'\n",
        "P -> 'at'\n",
        "DT -> 'the'\n",
        "ADV -> 'away'\n",
        "CC -> 'and'\n",
        "NN -> 'dog' | 'cat'\n",
        "ADJ -> 'big' | 'black' | 'white'\n",
        "\"\"\")\n",
        "\n",
        "tokens = nltk.tokenize.word_tokenize(\"the big black dog barked at the white cat and chased away\")\n",
        "\n",
        "parser = nltk.ChartParser(text3)\n",
        "for tree in parser.parse(tokens):\n",
        "  display(tree) # print"
      ],
      "metadata": {
        "id": "lVpSvjZUjail",
        "outputId": "1f555cf6-7893-47c8-d2d6-6627c5fb0df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('DT', ['the']), Tree('NOM', [Tree('ADJ', ['big']), Tree('ADJ', ['black']), Tree('NN', ['dog'])])]), Tree('VP', [Tree('VP', [Tree('VP', [Tree('V', ['barked'])]), Tree('PP', [Tree('P', ['at']), Tree('NP', [Tree('DT', ['the']), Tree('NOM', [Tree('ADJ', ['white']), Tree('NN', ['cat'])])])])]), Tree('CC', ['and']), Tree('VP', [Tree('V', ['chased']), Tree('ADV', ['away'])])])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,560.0,360.0\" width=\"560px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"31.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"22.7273%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.3636%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.2727%\" x=\"22.7273%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">big</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.1765%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">black</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.4118%\" x=\"70.5882%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">dog</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.2941%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.3636%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.7143%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"68.5714%\" x=\"31.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"60.4167%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"27.5862%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">barked</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.7931%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.4138%\" x=\"27.5862%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"19.0476%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">P</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">at</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.52381%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.9524%\" x=\"19.0476%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">white</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cat</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.5238%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.7931%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.2083%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"10.4167%\" x=\"60.4167%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.1667%\" x=\"70.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"57.1429%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chased</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.5714%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.8571%\" x=\"57.1429%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADV</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">away</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.5714%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.4167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('DT', ['the']), Tree('NOM', [Tree('ADJ', ['big']), Tree('NOM', [Tree('ADJ', ['black']), Tree('NN', ['dog'])])])]), Tree('VP', [Tree('VP', [Tree('VP', [Tree('V', ['barked'])]), Tree('PP', [Tree('P', ['at']), Tree('NP', [Tree('DT', ['the']), Tree('NOM', [Tree('ADJ', ['white']), Tree('NN', ['cat'])])])])]), Tree('CC', ['and']), Tree('VP', [Tree('V', ['chased']), Tree('ADV', ['away'])])])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,560.0,360.0\" width=\"560px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"31.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"22.7273%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.3636%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.2727%\" x=\"22.7273%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">big</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">black</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">dog</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.3636%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.7143%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"68.5714%\" x=\"31.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"60.4167%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"27.5862%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">barked</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.7931%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.4138%\" x=\"27.5862%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"19.0476%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">P</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">at</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.52381%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.9524%\" x=\"19.0476%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">white</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cat</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.5238%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.7931%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.2083%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"10.4167%\" x=\"60.4167%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.1667%\" x=\"70.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"57.1429%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chased</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.5714%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.8571%\" x=\"57.1429%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADV</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">away</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.5714%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.4167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {}
        }
      ]
    }
  ]
}