{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyZSlGjpxSMEm4Xjz+I/Es",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejini6969/Text-Analytics/blob/main/Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before doing text sentiment and analysis, open the file and output its content \n",
        "file = open(\"/content/Data_1.txt\")\n",
        "text = file.read()\n",
        "print(text)\n",
        "file.close()  # Close the file to prevent data loss and corruption"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wchk8DBuxX7p",
        "outputId": "f4d5435c-8b19-4cbf-d234-9a2549a21b75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is one thing to automatically detect that a particular word occurs in a text, and to\n",
            "display some words that appear in the same context. However, we can also determine\n",
            "the location of a word in the text: how many words from the beginning it appears. This\n",
            "positional information can be displayed using a dispersion plot. Each stripe represents\n",
            "an instance of a word, and each row represents the entire text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"\\n\", \" \") # replace line separators with spaces\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B24vBCbL9kpV",
        "outputId": "79c37757-1054-41f6-8002-51b6f49ef8ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Form tokenization"
      ],
      "metadata": {
        "id": "QfjoAXGzxR_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Demonstrate sentence segmentation and report the output. "
      ],
      "metadata": {
        "id": "2BV5O-qWw-OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk import sent_tokenize \n",
        "\n",
        "tokens = sent_tokenize(text)\n",
        "print(\"\\nThere are a total of\", len(tokens), \"sentences in the text file.\\n\")\n",
        "\n",
        "num = 1\n",
        "for sentence in tokens:\n",
        "  print(f'{num}. {sentence}\\n')\n",
        "  num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sQd2MtcxDBo",
        "outputId": "e7b7c1a4-aaa2-411a-e582-53e4e8e03c04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are a total of 4 sentences in the text file.\n",
            "\n",
            "1. It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.\n",
            "\n",
            "2. However, we can also determine the location of a word in the text: how many words from the beginning it appears.\n",
            "\n",
            "3. This positional information can be displayed using a dispersion plot.\n",
            "\n",
            "4. Each stripe represents an instance of a word, and each row represents the entire text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tDemonstrate word tokenisation using the split function, Regular Expression and NLTK packages separately and report the output."
      ],
      "metadata": {
        "id": "5HQO-Hmk9ff6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Python split() function\n",
        "word = text.split()\n",
        "print(word)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(word), \"words in the text file.\\n\")\n",
        "\n",
        "print(\"List of words that have leading or trailing punctuations: \\n\")\n",
        "num = 1\n",
        "for w in word:\n",
        "    for c in punctuation:\n",
        "      if w.startswith(c) or w.endswith(c):\n",
        "        print(f'{num}. {w}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "id": "N4AbMMLz9hmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7373637b-8b2d-4faa-88d2-74e183b7690a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text,', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context.', 'However,', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text:', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word,', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text.']\n",
            "\n",
            "There are a total of 72 words in the text file.\n",
            "\n",
            "List of words that have leading or trailing punctuations: \n",
            "\n",
            "1. text,\n",
            "\n",
            "2. context.\n",
            "\n",
            "3. However,\n",
            "\n",
            "4. text:\n",
            "\n",
            "5. appears.\n",
            "\n",
            "6. plot.\n",
            "\n",
            "7. word,\n",
            "\n",
            "8. text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Regular Expression\n",
        "import re\n",
        "tokens_2 = re.findall(\"\\w+\", text)\n",
        "print(tokens_2)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(tokens_2), \"words in the text file.\\n\")\n",
        "\n",
        "print(\"List of words that have leading or trailing punctuations: \\n\")\n",
        "num = 1\n",
        "for t in tokens_2:\n",
        "    for c in punctuation:\n",
        "      if t.startswith(c) or t.endswith(c):\n",
        "        print(f'{num}. {t}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PG6rZWEjPS0",
        "outputId": "62ad8b98-5041-449c-d38a-248409d5cb44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', 'However', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text']\n",
            "\n",
            "There are a total of 72 words in the text file.\n",
            "\n",
            "List of words that have leading or trailing punctuations: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens_3 = word_tokenize(text)\n",
        "print(tokens_3)\n",
        "\n",
        "print(\"\\nThere are a total of\", len(tokens_3), \"tokens in the text file.\\n\")\n",
        "\n",
        "num = 1\n",
        "for t in tokens_3:\n",
        "    if t in punctuation:\n",
        "        print(f'{num}. {t}\\n')\n",
        "        num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JfbM-yVtr1d",
        "outputId": "f4cdab88-e2c9-4e71-e57f-bb9a1a517d7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "\n",
            "There are a total of 80 tokens in the text file.\n",
            "\n",
            "1. ,\n",
            "\n",
            "2. .\n",
            "\n",
            "3. ,\n",
            "\n",
            "4. :\n",
            "\n",
            "5. .\n",
            "\n",
            "6. .\n",
            "\n",
            "7. ,\n",
            "\n",
            "8. .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Form word stemming "
      ],
      "metadata": {
        "id": "Rr3V2N4vw6pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tDemonstrate word stemming using Regular Expression, Porter Stemmer and Lancaster Stemmer and report the output. "
      ],
      "metadata": {
        "id": "h6wVWesN3Wpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "re_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "regexp = RegexpStemmer(\"(ly|ed|ing|ies|es|s|ment)$\")\n",
        "print(\"List of tokens before stemming:\\n\", tokens)\n",
        "for x in tokens:\n",
        "  r = regexp.stem(x)\n",
        "  re_lst.append(r)\n",
        "print(\"List of tokens after stemming:\\n\", re_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mSDdhet3av0",
        "outputId": "7b6a2d40-f532-4f1a-f10a-fba46bbd3f39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens before stemming:\n",
            " ['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "List of tokens after stemming:\n",
            " ['It', 'i', 'one', 'th', 'to', 'automatical', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'beginn', 'it', 'appear', '.', 'Thi', 'positional', 'information', 'can', 'be', 'display', 'us', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represent', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represent', 'the', 'entire', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ps_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "print(\"List of tokens before stemming:\\n\", tokens)\n",
        "for x in tokens:\n",
        "  ps_lst.append(ps.stem(x))\n",
        "print(\"List of tokens after stemming:\\n\", ps_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d09_f2Rx4Y7p",
        "outputId": "3300df40-b388-45ab-e882-c9c26c732829"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens before stemming:\n",
            " ['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "List of tokens after stemming:\n",
            " ['it', 'is', 'one', 'thing', 'to', 'automat', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'locat', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'mani', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'use', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'instanc', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lancaster Stemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "ls = LancasterStemmer()\n",
        "ls_lst = []\n",
        "tokens = word_tokenize(text)\n",
        "print(\"List of tokens before stemming:\\n\", tokens)\n",
        "for x in tokens:\n",
        "  ls_lst.append(ls.stem(x))\n",
        "print(\"List of tokens after stemming:\\n\", ls_lst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alQE59vt5HUe",
        "outputId": "1c575273-3050-427a-8f23-c04473923abf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens before stemming:\n",
            " ['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
            "List of tokens after stemming:\n",
            " ['it', 'is', 'on', 'thing', 'to', 'autom', 'detect', 'that', 'a', 'particul', 'word', 'occ', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'som', 'word', 'that', 'appear', 'in', 'the', 'sam', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'loc', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'us', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'inst', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tExplain the differences among Regular Expression stemmer, Porter Stemmer and Lancaster Stemmer using the obtained output"
      ],
      "metadata": {
        "id": "Gily_ER6BBUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Row number       Original token          Regular Expression          Porter Stemmer          Lancaster Stemmer\")\n",
        "\n",
        "i = 1\n",
        "tokens = word_tokenize(text)\n",
        "for t, r, p, l in zip(tokens, re_lst, ps_lst, ls_lst):\n",
        "  if r != p or p != l or r != l:\n",
        "    print(str(i).ljust(20, ' '), t.ljust(25, ' '), r.ljust(25, ' '), p.ljust(25, ' '), l)\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umpiHpbN7yCm",
        "outputId": "31366db5-2c87-4634-d326-b9c53147821a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row number       Original token          Regular Expression          Porter Stemmer          Lancaster Stemmer\n",
            "1                    It                        It                        it                        it\n",
            "2                    is                        i                         is                        is\n",
            "3                    one                       one                       one                       on\n",
            "4                    thing                     th                        thing                     thing\n",
            "5                    automatically             automatical               automat                   autom\n",
            "6                    particular                particular                particular                particul\n",
            "7                    occurs                    occur                     occur                     occ\n",
            "8                    some                      some                      some                      som\n",
            "9                    same                      same                      same                      sam\n",
            "10                   However                   However                   howev                     howev\n",
            "11                   determine                 determine                 determin                  determin\n",
            "12                   location                  location                  locat                     loc\n",
            "13                   many                      many                      mani                      many\n",
            "14                   beginning                 beginn                    begin                     begin\n",
            "15                   This                      Thi                       thi                       thi\n",
            "16                   positional                positional                posit                     posit\n",
            "17                   information               information               inform                    inform\n",
            "18                   using                     us                        use                       us\n",
            "19                   dispersion                dispersion                dispers                   dispers\n",
            "20                   Each                      Each                      each                      each\n",
            "21                   represents                represent                 repres                    repres\n",
            "22                   instance                  instance                  instanc                   inst\n",
            "23                   represents                represent                 repres                    repres\n",
            "24                   entire                    entire                    entir                     entir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Filter stop words and punctuation "
      ],
      "metadata": {
        "id": "ipmAWFhbDe11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tDemonstrate stop words and punctuations removal from the given text corpus and report the output suitably. "
      ],
      "metadata": {
        "id": "t8xG5wgQDffQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words removal\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "stoptokens = nltk.corpus.stopwords.words(\"english\") # list of stopwords\n",
        "tokens = word_tokenize(text.lower()) # must convert to lowercase first since all stop words in nltk corpus are lowercase\n",
        "\n",
        "print(\"Text before stop words removal:\\n\\n\", text, \"\\n\")\n",
        "sw_removal = \"\"\n",
        "for w in tokens:\n",
        "  if w not in stoptokens:\n",
        "    sw_removal += w + \" \"\n",
        "print(\"Text after stop words removal:\\n\\n\", sw_removal, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB1jMqxvDiG3",
        "outputId": "87815853-b2f0-4e73-f48e-7924e1cd8213"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before stop words removal:\n",
            "\n",
            " It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. \n",
            "\n",
            "Text after stop words removal:\n",
            "\n",
            " one thing automatically detect particular word occurs text , display words appear context . however , also determine location word text : many words beginning appears . positional information displayed using dispersion plot . stripe represents instance word , row represents entire text .  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuation removal\n",
        "from string import punctuation\n",
        "\n",
        "print(\"Text before punctuation removal:\\n\\n\", sw_removal)\n",
        "pct_removal = \"\"\n",
        "for c in sw_removal:\n",
        "  if c not in punctuation:\n",
        "    pct_removal += c\n",
        "print(\"\\nText after punctuation removal:\\n\\n\", pct_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Q9PjO3Lpdr",
        "outputId": "91f1a0d9-1eaf-4360-86e1-75370fb110ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before punctuation removal:\n",
            "\n",
            " one thing automatically detect particular word occurs text , display words appear context . however , also determine location word text : many words beginning appears . positional information displayed using dispersion plot . stripe represents instance word , row represents entire text . \n",
            "\n",
            "Text after punctuation removal:\n",
            "\n",
            " one thing automatically detect particular word occurs text  display words appear context  however  also determine location word text  many words beginning appears  positional information displayed using dispersion plot  stripe represents instance word  row represents entire text  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tReport the stop words found in the given text corpus. "
      ],
      "metadata": {
        "id": "f9dRJiPnutEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "stoptokens = nltk.corpus.stopwords.words(\"english\") # list of stopwords\n",
        "print(\"All stop words found in NLTK corpus:\\n\", stoptokens, \"\\n\")\n",
        "\n",
        "print(\"List of stop words found in the text corpus: \\n\")\n",
        "num = 1\n",
        "tokens = word_tokenize(text.lower()) # must convert to lowercase first since all stop words in nltk corpus are lowercase\n",
        "for x in tokens:\n",
        "  if x in stoptokens:\n",
        "    print(f'{num}. {x}')\n",
        "    num += 1\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "suoB154jurye",
        "outputId": "7ed79b94-abd5-44e2-f836-05198d11c92e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All stop words found in NLTK corpus:\n",
            " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"] \n",
            "\n",
            "List of stop words found in the text corpus: \n",
            "\n",
            "1. it\n",
            "2. is\n",
            "3. to\n",
            "4. that\n",
            "5. a\n",
            "6. in\n",
            "7. a\n",
            "8. and\n",
            "9. to\n",
            "10. some\n",
            "11. that\n",
            "12. in\n",
            "13. the\n",
            "14. same\n",
            "15. we\n",
            "16. can\n",
            "17. the\n",
            "18. of\n",
            "19. a\n",
            "20. in\n",
            "21. the\n",
            "22. how\n",
            "23. from\n",
            "24. the\n",
            "25. it\n",
            "26. this\n",
            "27. can\n",
            "28. be\n",
            "29. a\n",
            "30. each\n",
            "31. an\n",
            "32. of\n",
            "33. a\n",
            "34. and\n",
            "35. each\n",
            "36. the\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Form Parts of Speech (POS) taggers & Syntactic Analysers "
      ],
      "metadata": {
        "id": "ETA4B5ndzD8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before doing text sentiment and analysis, open the file and output its content \n",
        "file = open(\"/content/Data_2.txt\")\n",
        "text2 = file.read()\n",
        "print(text2)\n",
        "file.close()  # Close the file to prevent data loss and corruption"
      ],
      "metadata": {
        "id": "OonIQlDIzZrz",
        "outputId": "31ad3f8b-9220-4dd0-a88d-ac794f78f427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The big black dog barked at the white cat and chased away.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tDemonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output"
      ],
      "metadata": {
        "id": "VxIYaRJnzPaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK POS tagger\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"tagsets\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text2)\n",
        "nltk_pos = nltk.pos_tag(tokens)\n",
        "print(nltk_pos, \"\\n\")"
      ],
      "metadata": {
        "id": "JYL4epA3zDSY",
        "outputId": "f4d56ec5-9f3a-4ad7-b1d8-0f43690530ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB'), ('.', '.')] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# textblob POS tagger\n",
        "from textblob import TextBlob\n",
        "tokens = TextBlob(text2)\n",
        "textblob_pos = tokens.tags\n",
        "print(textblob_pos)"
      ],
      "metadata": {
        "id": "tL34HeiO5bbx",
        "outputId": "4d172d47-ace8-45e7-84f9-5ad1f0602ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Expression tagger\n",
        "from nltk.tag.sequential import RegexpTagger as RegT\n",
        "\n",
        "patterns = [\n",
        "     (r'.*ing$', 'VBG'),               # gerunds\n",
        "     (r'.*ed$', 'VBD'),                # simple past\n",
        "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
        "     (r'.*ould(n\\'t)?$', 'MD'),        # modals\n",
        "     (r'.*(\\'s|s\\')$', 'NN$'),         # possessive nouns\n",
        "     (r'.*s$', 'NNS'),                 # plural nouns\n",
        "     (r'^-?\\d+(.\\d+)?$', 'CD'),        # cardinal numbers\n",
        "     (r'.*ment$', 'NN'),               # i.e. wonderment\n",
        "     (r'.*ful$', 'JJ'),                # i.e. wonderful\n",
        "     (r'.*', 'NN')                     # nouns (default)\n",
        " ]\n",
        "\n",
        "tagger = RegT(patterns)\n",
        "tokens = word_tokenize(text2)\n",
        "regex_pos = tagger.tag(tokens)\n",
        "print(regex_pos)             "
      ],
      "metadata": {
        "id": "3wvW840y5w7j",
        "outputId": "bf98d3bf-2afc-4ecc-d59e-a54237bf9318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'NN'), ('big', 'NN'), ('black', 'NN'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'NN'), ('the', 'NN'), ('white', 'NN'), ('cat', 'NN'), ('and', 'NN'), ('chased', 'VBD'), ('away', 'NN'), ('.', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tExplain the differences of the POS taggers using the output obtained in the above question"
      ],
      "metadata": {
        "id": "JSu_kmFpArFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"          \".join(x for x in [\"tokens\", \"NLTK POS tagger\", \"Textblob POS tagger\", \"Regular Expression POS tagger\"]))\n",
        "\n",
        "for x, y, z in zip(nltk_pos, textblob_pos, regex_pos):\n",
        "  print(x[0].ljust(20, ' '), x[1].ljust(25, ' '), y[1].ljust(30, ' '), z[1])"
      ],
      "metadata": {
        "id": "ZbMlvmz__KQe",
        "outputId": "39e4c8ca-50a5-42f8-d7a0-292cdafb04b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens          NLTK POS tagger          Textblob POS tagger          Regular Expression POS tagger\n",
            "The                  DT                        DT                             NN\n",
            "big                  JJ                        JJ                             NN\n",
            "black                JJ                        JJ                             NN\n",
            "dog                  NN                        NN                             NN\n",
            "barked               VBD                       VBD                            VBD\n",
            "at                   IN                        IN                             NN\n",
            "the                  DT                        DT                             NN\n",
            "white                JJ                        JJ                             NN\n",
            "cat                  NN                        NN                             NN\n",
            "and                  CC                        CC                             NN\n",
            "chased               VBD                       VBD                            VBD\n",
            "away                 RB                        RB                             NN\n"
          ]
        }
      ]
    }
  ]
}